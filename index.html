<!DOCTYPE HTML>
<!--
Read Only by HTML5 UP
html5up.net | @ajlkn
Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->

<html>
    <head>
        <title>ALA 2022</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
        <link rel="stylesheet" href="assets/css/main.css" />
        <link rel="icon" type="image/png" href="images/icons/robot.png"/>
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-3WQZBEV8XB"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'G-3WQZBEV8XB');
        </script>
        
    </head>
    <body class="is-preload">
        
        <!-- Header -->
        <section id="header">
            <header>
                <!--<span class="image avatar"><img src="images/avatar.jpg" alt="" /></span>-->
                <h1 id="logo"><a href="#">ALA 2022</a></h1>
                <p style="color:#FFF2D2">Adaptive and Learning Agents Workshop<br />
                at AAMAS, Auckland, NZ </p>
            </header>
            <nav id="nav">
                <ul>
                    <li><a href="#news" class="active">News</a></li>
                    <li><a href="#about">About</a></li>
                    <li><a href="#dates">Important Dates</a></li>
                    <li><a href="#submission">Submission Details</a></li>
                    <li><a href="#challenge">ALA-Cogment Challenge</a></li>
                    <li><a href="#journal">Journal Special Issue</a></li>
                    <!--<li><a href="#program">Program</a></li>
                    <li><a href="#accepted">Accepted Papers</a></li> -->
                    <li><a href="#talks">Invited Talks</a></li>
                    <li><a href="#pc">Program Committee</a></li>
                    <li><a href="#organization">Organization</a></li>
                    <li><a href="#sponsor">Sponsorship</a></li>
                    <li><a href="#ai_ethics">AI & Ethics</a></li>
                    <li><a href="#contact">Contact</a></li>
                    
                </ul>
            </nav>
            <footer>
                <ul class="icons">
                    <li><a href="https://www.linkedin.com/groups/4412140/" class="icon fa-linkedin"><span class="label">Linkedin</span></a></li>
                    <li><a href="mailto:ala.workshop.2022@gmail.com" class="icon fa-envelope"><span class="label">Email</span></a></li>
                </ul>
            </footer>
        </section>
        
        <!-- Wrapper -->
        <div id="wrapper">
            
            <!-- Main -->
            <!-- News -->
            <section id="news">
                <div id="main">
                    <div class="image main" data-position="top">
                        <img src="images/banner2.png" alt=""/>
                        <h2 id="banner-header" style="color:#FFF2D2">ALA 2022</h2>
                        <h3 id="banner-description" style="color:#FFF2D2">9 &amp; 10 May 2022, Auckland, NZ</h3>
                    </div>
                    <div class="container">
                        <h3>News</h3>
                        <ul>
                            <li>11 Apr 2022: We are also excited to announce Patrick MacAlpine of Sony AI will be giving a talk/demo on Sony AI's recent paper "Outracing Champion Gran Turismo Drivers with Deep Reinforcement Learning".</li>
                            <li>11 Apr 2022: We are excited to announce Bei Peng as a keynote speaker for ALA 2022.</li>
                            <li>16 Feb 2022: We are excited to announce Natasha Jaques as a keynote speaker for ALA 2022. </li>
                            <li>01 Feb 2022: <a href="https://ai-r.com/aamas-2022-welcome-to-the-ala-cogment-challenge/" target="_blank">ALA-Cogment Challenge goes live! </a></li>
                            <li>28 Jan 2022: ALA 2022 submission deadline has been extended to 11 Feb 2022 23:59 UTC </a></li>
                            <li>6 Dec 2021: ALA 2022 Call for papers can be found <a href="https://easychair.org/cfp/ALA-2022" target="_blank">here</a></li>
                            <li>25 Nov 2021: ALA 2022 Website goes live!</li>
                            <!--
                            <li>08 May 2020: The ALA presentations are now available on <a href="https://www.underline.io/conferences/19?trackId=19&subTrackId=25#lectures" target ="_blank">underline</a>!</li>
                            <li>4 May 2020: The <a href="#program">preliminary program</a> for the live events is now online! The ALA live sessions will be streamed on <a href="https://www.twitch.tv/ala2020workshop" target="_blank"><b>Twitch</b></a>!</li>
                          <li>22 March 2017: The list of accepted papers is now online.</li>
                           <li>22 March 2017: The list of <a href="#accepted">accepted papers</a> is now online.</li>
                            <li> 27 April 2020: We are happy to announce our <a href="#talks">invited speakers</a> for this year, <a href="http://roijers.info" target="_blank">Diederik M. Roijers</a> and <a href="https://www.jakobfoerster.com" target="_blank">Jakob Foerster</a>!</li>
                            <li> 27 April 2020: We invite all authors and participants to join our <a href="https://join.slack.com/t/ala2020/shared_invite/zt-dn4qmm5j-oEsYxzRpmUTz6cMmt9lPSw" target="_blank">Slack workspace</a>! Check out the <a href="#program">program</a> for more details.</li>
                            <li>15 April 2020: We are happy to announce that ALA will take place this year as a virtual workshop. The content will consist of a mix of pre-recorded contributions together with live Q&A sessions and invited speaker presentations.</li>
                            <li>18 March 2020: AAMAS has decided to move to a <a href="https://aamas2020.conference.auckland.ac.nz/news-and-events/" target="_blank">virtual only conference</a> this year. We will delay the paper notifications until we will receive further news and instructions on how AAMAS decides to organise the workshops under these circumstances. We will make sure to provide all the information <strong>before April 1.</strong></li>
                            <li>21 January 2020: <a href='#submission'>We recommend authors to also append reviews received for AAMAS submissions</a></li>
                            
                            <li>25 February 2022: Submissions are now closed. We received <strong>62 submissions</strong> this year!</li>
                            <li>5 February 2022: The <a href='#dates'>submission deadline</a> has been extended to <strong>24 February 2022 23:59 UTC</strong>!</li>
                            <li>5 January 2022: <a href='#pc'>Program Committee</a> members added</li>
                            <li>23 November 2020: ALA 2022 site launched</li>-->
                        </ul>
                    </div>
                    </section>
            <!-- One -->
            <section id="about">
                <div class="container">
                    <header class="major">
                        <h3>ALA 2022 - Workshop at <a href="https://aamas2022-conference.auckland.ac.nz/" target="_blank">AAMAS 2022</a></h3>
                        <p align="justify">Adaptive and Learning Agents (ALA) encompasses diverse fields such as Computer Science, Software Engineering, Biology, as well as
                        Cognitive and Social Sciences. The ALA workshop will focus on agents and multiagent systems which employ learning or adaptation.</p>
                    </header>
                    <p align="justify">This workshop is a continuation of the long running AAMAS series of workshops on adaptive agents, now in its fourteenth year. Previous editions of this workshop may be found at the following urls:</p>
                    <ul>
                        <li><a href="http://ala2021.vub.ac.be" target="_blank">ALA-21</a></li>
                        <li><a href="http://ala2020.vub.ac.be" target="_blank">ALA-20</a></li>
                        <li><a href="http://ala2019.vub.ac.be" target="_blank">ALA-19</a></li>
                        <li><a href="http://ala2018.it.nuigalway.ie" target="_blank">ALA-18</a></li>
                        <li><a href="http://ala2017.it.nuigalway.ie/" target="_blank">ALA-17</a></li>
                        <li><a href="http://ala2016.csc.liv.ac.uk/" target="_blank">ALA-16</a></li>
                        <li><a href="http://ala2015.csc.liv.ac.uk/" target="_blank">ALA-15</a></li>
                        <li><a href="http://swarmlab.unimaas.nl/ala2014/" target="_blank">ALA-14</a></li>
                        <li><a href="http://swarmlab.unimaas.nl/ala2013/" target="_blank">ALA-13</a></li>
                        <li><a href="http://ai.vub.ac.be/ALA2012/" target="_blank">ALA-12</a></li>
                        <li><a href="http://como.vub.ac.be/ALA2011/" target="_blank">ALA-11</a></li>
                        <li><a href="http://www-users.cs.york.ac.uk/%7Ekudenko/ala10/" target="_blank">ALA-10</a></li>
                        <li><a href="http://teamcore.usc.edu/taylorm/ALA09/" target="_blank">ALA-09</a></li>
                        <li><a href="http://ki.informatik.uni-wuerzburg.de/%7Ekluegl/ALAMAS.ALAg/" target="_blank">ALAMAS+ALAg-08</a></li>
                        <li><a href="http://web.engr.oregonstate.edu/%7Ektumer/conferences/alag07.html" target="_blank">ALAg-07</a></li>
                        <!--  <li><a href="http://www.cs.unimaas.nl/alamas/">ALAMAS-07</a></li> -->
                        <li><a href="http://www-users.cs.york.ac.uk/%7Ekazakov/aamas/">Earlier editions</a> </li>
                    </ul>
                    <p align="justify">The goal of this workshop is to increase awareness of and interest in adaptive agent research, encourage collaboration and give a representative overview of current research in the area of adaptive and learning agents and multi-agent systems. It aims at bringing together not only scientists from different areas of computer science (e.g. agent architectures, reinforcement learning, evolutionary algorithms) but also from different fields studying similar concepts (e.g. game theory, bio-inspired control, mechanism design).</p>
                    
                    <p align="justify">The workshop will serve as an inclusive forum for the discussion of ongoing or completed work covering both theoretical and practical aspects of adaptive and learning agents and multi-agent systems.</p>
                    
                    <p align="justify">This workshop will focus on all aspects of adaptive and learning agents and multi-agent systems with a particular amphasis on how to modify established learning techniques and/or create new learning paradigms to address the many challenges presented by complex real-world problems. The topics of interest include but are not limited to:</p>
                    
                    <ul>
                        <li>Novel combinations of reinforcement and supervised learning approaches</li>
                        <li>Integrated learning approaches that work with other agent reasoning modules like negotiation, trust models, coordination, etc.</li>
                        <li>Supervised multi-agent learning</li>
                        <li>Reinforcement learning (single- and multi-agent)</li>
                        <li>Novel deep learning approaches for adaptive single- and multi-agent systems</li>
                        <li>Multi-objective optimisation in single- and multi-agent systems</li>
                        <li>Planning (single- and multi-agent)</li>
                        <li>Reasoning (single- and multi-agent)</li>
                        <li>Distributed learning</li>
                        <li>Adaptation and learning in dynamic environments</li>
                        <li>Evolution of agents in complex environments</li>
                        <li>Co-evolution of agents in a multi-agent setting</li>
                        <li>Cooperative exploration and learning to cooperate and collaborate</li>
                        <li>Learning trust and reputation</li>
                        <li>Communication restrictions and their impact on multi-agent coordination</li>
                        <li>Design of reward structure and fitness measures for coordination</li>
                        <li>Scaling learning techniques to large systems of learning and adaptive agents</li>
                        <li>Emergent behaviour in adaptive multi-agent systems</li>
                        <li>Game theoretical analysis of adaptive multi-agent systems</li>
                        <li>Neuro-control in multi-agent systems</li>
                        <li>Bio-inspired multi-agent systems</li>
                        <li>Applications of adaptive and learning agents and multi-agent systems to real world complex systems</li>
                    </ul>
                    
                    <p align="justify">Extended and revised versions of papers presented at the workshop will be eligible for inclusion in a journal special issue (see below).</p>
                    <p class="entry-footer"></p>
                </div>
            </section>
            
            <!-- Two -->
            <section id="dates">
                <div class="container">
                    <h3>Important Dates</h3>
                    
                    <ul class="feature-icons">
                        
                        <li class="fa-telegram">Submission Deadline:   <s> 30 January 2022</s>
                            &nbsp;&nbsp;<font color="#4872A6"><b>11 February 2022 23:59 UTC</b></font></li>
                        
                        <li class="fa-bell">Notification of acceptance: <font color="#4872A6"><b>14 March  2022 </b></font>
                        <li class="fa-file-pdf-o">Camera-ready copies: <font color="#4872A6"><b>15 April 2022</b></font>
                        <li class="fa-users">Workshop:            <b>9 - 10 May 2022</b></li>
                    
                    </ul>
                </div>
            </section>
            
            <!-- Three -->
            <section id="submission">
                <div class="container">
                    <h3>Submission Details</h3>
                    <p align="justify">Papers can be submitted through <a href="https://easychair.org/conferences/?conf=ala20220" alt="" target="_blank">EasyChair</a>.</p>
                    <p align="justify">We invite submission of original work, up to 8 pages in length (excluding references) in the ACM proceedings format (i.e. following the AAMAS formatting instructions). This includes work that has been accepted as a poster/extended abstract at AAMAS 2022. Additionally, we welcome submission of preliminary results, i.e. work-in-progress, as well as visionary outlook papers that lay out directions for future research in a specific area, both up to 6 pages in length, although shorter papers are very much welcome, and will not be judged differently. Finally, we also accept recently published journal papers in the form of a 2 page abstract.</p>
                    <p align="justify">Furthermore, <strong> for submissions that were rejected or accepted as extended abstracts at AAMAS</strong>, we encourage authors to also append the received reviews. This is simply a recommendation and it is optional. Authors can also include a short note or changelist they carried out on the paper. The reviews can be appended at the end of the submission file and do not count towards the page limit.</p>
                    <p align="justify">All submissions will be peer-reviewed (single-blind). Accepted work will be allocated time for poster and possibly oral presentation during the workshop. Extended versions of original papers presented at the workshop will also be eligible for inclusion in a post-proceedings journal special issue.  </p>

                    <p align="justify">When preparing your submission for ALA 2022, please be sure to remove the AAMAS copyright block, citation information and running headers. Please replace the AAMAS copyright block in the main.tex file from the AAMAS template with the following:
<pre>
\setcopyright{none}
\acmConference[ALA '22]{Proc.\@ of the Adaptive and Learning Agents Workshop (ALA 2022)}
{May 9-10, 2022}{Online, \url{https://ala2022.github.io/}}{Cruz, Hayes, da Silva, Santos (eds.)}
\copyrightyear{2022}
\acmYear{2022}
\acmDOI{}
\acmPrice{}
\acmISBN{}
\settopmatter{printacmref=false}
</pre>

                    </p>
                </div>
            </section>

            <!-- Three -->
            <section id="challenge">
                <div class="container">
                    <h3>ALA-Cogment Challenge</h3>
                    <p align="justify">All accepted ALA papers will be eligable to take part in the <a href="https://ai-r.com/aamas-2022-welcome-to-the-ala-cogment-challenge/" alt="" target="_blank">ALA-Cogment Challenge</a>. The ALA-Cogment Challenge offers a total prize pool of $10,000. </p>

                    <p align="justify">Cogment is an open-source framework for distributed multi-actor training, deployment, and operations. To take part in the competition you must submit a paper to ALA by 11-Feb-2022. Then all accepted ALA particiapants must, by April 30, 2022:

                        <ul>
                        <li> Sign up for the <a href="https://eyrwknioxo8.typeform.com/to/j4jMvQxp" alt="" target="_blank">ALA-Cogment Challenge.</a></li>
                        <li>Cite Cogment in your paper.</li>
                        <li>Implement an experimental setup using Cogment for your submitted paper and share it with the ALA-Cogment Challenge evaluation team (e.g. in a GitHub repo or in a zip file). We strongly encourage authors to publish their code to meet this requirement.</li>
                        </ul>


                    </p>


                    <p align="justify">We will award up to three grand prizes to ALA-Cogment Challenge submissions that make the best use of Cogment for applications or for fundamental research. Grand prizes will be awarded according to criteria that include (but are not limited to):

                        <ul>
                        <li>The richness of the submission’s Cogment usage with respect to agents, implementations, environments, benchmarking, and evaluations.</li>
                        <li>The creative involvement of human actors or evaluators during the submission’s Cogment training or validation process. </li>
                        <li>The complexity of the AI problem being addressed with Cogment.</li>
                        </ul>

                    We will announce the grand prize results live during the May 9-10, 2022 workshop. Further details about the competition can be found here: <a href="https://ai-r.com/aamas-2022-welcome-to-the-ala-cogment-challenge/" alt="" target="_blank">https://ai-r.com/aamas-2022-welcome-to-the-ala-cogment-challenge/</a>
                    </p>


                    
                </div>
            </section>
            
            <!-- Four -->
            <section id="journal">
                <div class="container">
                    <h3>Journal Special Issue</h3>
                    
                    <p align="justify">We are delighted to announce that extended versions of all original contributions at ALA 2022 will be eligible for inclusion in a special issue of the Springer journal <a href="https://www.springer.com/computer/ai/journal/521" alt="https://www.springer.com/computer/ai/journal/521" target="_blank">Neural Computing and Applications</a> (Impact Factor 5.606). The deadline for submitting extended papers will be 15 September 2022.</p>
                    <a href="https://www.springer.com/computer/ai/journal/521" target='_blank'><img src='images/nca.jpg' height='200px' alt='NCA' /></a>
                    
                    <p align="justify">We will post further details about the submission process and expected publication timeline here after the workshop.</p>
                    <p class="entry-footer"></p>
                    
                </div>
            </section>
            
            <!-- Five -->
            <section id="program">
                <div class="container">
                    <h3>Program</h3>
                    <p>TBA</p>
                   <!-- <p>Except for the invited talks, ALA will take place in an asynchronous manner. In order to facilitate discussions over all the contributions as well as social interactions, we invite all authors and participants to join our <a href="https://join.slack.com/t/ala2020/shared_invite/zt-dn4qmm5j-oEsYxzRpmUTz6cMmt9lPSw" target="_blank">Slack workspace</a>.</p>
                    <p>In order to organise discussions, we ask authors/participants to create channels with the name <em>paper-#</em>. We have added below a unique number for each contribution.</p>
                    
                    <p> The ALA live sessions will be streamed on <a href="https://www.twitch.tv/ala2020workshop" target="_blank"><b>Twitch</b></a>.<p>
                    <p><b>Saturday 9 May</b></p>
                    <table width="100%" >
                        <tr>
                            <td>15:45 - 16:00 UTC</td>
                            <td><b>Welcome &amp; Opening Remarks</b>
                                </tr>
                        
                        <tr>
                            <td>16:00 - 17:00 UTC</td>
                            <td><b>Invited Talk: Jakob N. Foerster</b><br/><em><a href="#talks">Self-Play and Zero-Shot Coordination in Hanabi</a></em></td>
                        </tr>
                        <tr>
                            <td>17:00 - 18:00 UTC</td>
                            <td><b>Discussion Panel</b><br/>
                                <b>Topic:</b> Building an AI syllabus <br/>
                                <b>Chair:</b> Diederik M. Roijers (HU University of Applied Sciences Utrecht, Vrije Universiteit Brussel) <br/>
                                <b>Panelists:</b>
                                <ul>
                                    <li>Ann Now&eacute (Vrije Universiteit Brussel)</li>
                                    <li>Matt Taylor (University of Alberta)</li>
                                    <li>Senthil Yogamani (<a href="https://www.valeo.com/en/" target="_blank">Valeo<a>)</li>
                                    <li>Peter Stone (University of Texas at Austin)</li>
                                </ul>
                            </td>
                        </tr>
                        
                    </table>
                    <p><b>Sunday 10 May</b></p>
                    <table width="100%" >
                        <tr>
                            <td>09:00 - 10:00 UTC</td>
                            <td><b>Invited Talk: Diederik M. Roijers</b><br/><em><a href="#talks">Multi-objective decision making: why, how, and what now?</a></em></td>
                        </tr>
                        <tr>
                            <td>10:00 - 10:30 UTC</td>
                            <td><b>Awards, closing remarks and ALA 2022</b> </br>
                                <b> Best Paper Award:</b><br/> Silviu Pitis, Harris Chan, Stephen Zhao, Bradly Stadie and Jimmy Ba, <br/><em><a target='_blank' href='papers/ALA2020_paper_25.pdf'> Maximum Entropy Gain Exploration for Long Horizon Multi-goal Reinforcement Learning</a></em>
                        </tr>
                    </table>
                </div>
            </section> -->
            <!--<a href="docs/ALA2019_schedule_web.pdf" target="_blank">Download schedule as .pdf</a>-->
            <!--<p><b>Monday 13 May (Location: Room MB 9B)</b></p>
            
            <table width="100%" >
            <tr>
            <td width="18%"><b>08:45 - 09:00</b></td>
            <td><b>Welcome &amp; Opening Remarks</b>
            </tr>
            
            <tr>
            <td width="18%"><b>09:00 - 10:30</b></td>
            <td><b>Session I - Chair: Patrick Mannion</b></td>
            </tr>
            <tr>
            <td>09:00 - 10:00</td>
            <td>Invited Talk: Garrett Warnell<br/><em><a href="#talks">Human-in-the-Loop Machine Learning for Autonomy</a><em></td>
            </tr>
            <tr>
            <td>10:00 - 10:30<br></td>
            <td>Long Talk: Gabriel de La Cruz, Yunshu Du and Matthew E. Taylor<br><em><a target="_blank" href="papers/ALA2019_paper_14.pdf">Jointly Pre-training with Supervised, Autoencoder, and Value Losses for Deep Reinforcement Learning</a></em></td>
            </tr>
            
            <tr>
            <td><b>10:30 - 11:00</b></td>
            <td><b>Coffee Break</b></td>
            </tr>
            
            <tr>
            <td><b>11:00 - 12:30</b></td>
            <td><b>Session II - Chair: Fernando P. Santos</b></td>
            </tr>
            <tr>
            <td>11:00 - 11:30<br></td>
            <td>Long Talk: Bilal Kartal, Pablo Hernandez-Leal, Chao Gao and Matthew E. Taylor<br><em><a target="_blank" href="papers/ALA2019_paper_26.pdf">Safer Deep RL with Shallow MCTS: A Case Study in Pommerman</a></em></td>
            </tr>
            <tr>
            <td>11:30 - 12:00<br></td>
            <td>Long Talk: Felipe Leno Da Silva, Anna Helena Reali Costa and Peter Stone<br> <em><a target="_blank" href="papers/ALA2019_paper_1.pdf">Distributional Reinforcement Learning Applied to Robot Soccer Simulation</a></em></td>
            </tr>
            <tr>
            <td>12:00 - 12:15</td>
            <td>Short Talk: Miguel Suau, Elena Congeduti, Rolf A.N. Starre, Aleksander Czechowski and Frans A. Oliehoek<br><em><a target="_blank" href="papers/ALA2019_paper_35.pdf">Influence Based Abstraction in Deep Reinforcement Learning</a></em></td>
            </tr>
            <tr>
            <td>12:15 - 12:30</td>
            <td>Short Talk: Aleksandra Malysheva, Aleksei Shpilman and Daniel Kudenko<br><em><a target="_blank" href="papers/ALA2019_paper_17.pdf">MAGNet: Multi-agent Graph Network for Deep Multi-agentReinforcement Learning</a></em></td>
            </tr>
            <tr>
            <td><b>12:30 - 14:00</b></td>
            <td><b>Lunch</b></td>
            </tr>
            
            <tr>
            <td><b>14:00 - 15:30</b></td>
            <td><b>Session III - Chair: Felipe Leno Da Silva</b></td>
            </tr>
            <tr>
            <td>14:00 - 14:30<br></td>
            <td>Long Talk: Johan Källström and Fredrik Heintz<br> <em><a target="_blank" href="papers/ALA2019_paper_12.pdf">Tunable Dynamics in Agent-Based Simulation using Multi-Objective Reinforcement Learning</a></em> <b>(Best Paper Award Winner)</b> </td>
            </tr>
            <tr>
            <td>14:30 - 15:00<br></td>
            <td>Long Talk: Roxana R&#259;dulescu, Patrick Mannion, Diederik M. Roijers and Ann Now&eacute;<br> <em><a target="_blank" href="papers/ALA2019_paper_29.pdf">Equilibria in Multi-Objective Games: a Utility-Based Perspective</a></em></td>
            </tr>
            <tr>
            <td>15:00 - 15:15<br></td>
            <td>Short Talk: Mathieu Reymond and Ann Now&eacute;<br> <em><a target="_blank" href="papers/ALA2019_paper_36.pdf">Pareto-DQN: Approximating the Pareto front in complex multi-objective decision problems</a></em></td>
            </tr>
            <tr>
            <td>15:15 - 15:30<br></td>
            <td>Short Talk: Ruiyang Xu and Karl Lieberherr<br> <em><a target="_blank" href="papers/ALA2019_paper_11.pdf">Learning Self-Game-Play Agents for Combinatorial Optimization Problems</a></em></td>
            </tr>
            
            <tr>
            <td><b>15:30 - 16:00</b></td>
            <td><b>Coffee Break</b></td>
            </tr>
            
            <tr>
            <td><b>16:00 - 18:00</b></td>
            <td><b><a href="#posterA">Poster Session A</a></b></td>
            </tr>
            
            <tr>
            <td><b>19:00 - ...</b></td>
            <td><b>ALA Social Event</b><br>
            The ALA social event will be held at the Hurley's Irish Pub. Here is the location: <a target="_blank" href="https://goo.gl/maps/zVn3byadYz94JoQC7">https://goo.gl/maps/zVn3byadYz94JoQC7</a></td>
            </tr>
            
            </table>
            
            <p><b>Tuesday 14 May (Location: Room MB 9B)</b></p>
            
            <table width="100%" >
            
            <td width="18%"><b>09:00 - 10:30</b></td>
            <td><b>Session IV - Chair: Roxana R&#259;dulescu</b></td>
            </tr>
            <tr>
            <td>09:00 - 09:30</td>
            <td>Contributed Talk: Julian Garcia<br><em><a target="_blank" href="papers/ALA2019_paper_23.pdf">No winning strategy in the Iterated Prisoner's Dilemma: Game Theory and Simulated Evolution</a></em></td>
            </tr>
            <tr>
            <td>09:30 - 10:00<br></td>
            <td>Long Talk: Daan Bloembergen and Fernando Santos<br><em><a target="_blank" href="papers/ALA2019_paper_20.pdf">Moderate Responder Committees Maximize Fairness in (NxM)-Person Ultimatum Games</a></em></td>
            </tr>
            <tr>
            <td>10:00 - 10:15</td>
            <td>Short Talk: Panayiotis Danassis, Aris Filos-Ratsikas and Boi Faltings<br><em><a target="_blank" href="papers/ALA2019_paper_10.pdf">Anytime Heuristic for Weighted Matching Through Altruism-Inspired Behavior</a></em></td>
            </tr>
            <tr>
            <td>10:15 - 10:30</td>
            <td>Short Talk: David Mguni<br><em><a target="_blank" href="papers/ALA2019_paper_31.pdf">Efficient Reinforcement Dynamic Mechanism Design</a></em></td>
            </tr>
            
            <tr>
            <td><b>10:30 - 11:00</b></td>
            <td><b>Coffee Break</b></td>
            </tr>
            
            <tr>
            <td><b>11:00 - 12:30</b></td>
            <td><b>Session V - Chair: Pieter Libin</b></td>
            </tr>
            <tr>
            <td>11:00 - 11:30<br></td>
            <td>Long Talk: Koji Fukuda<br><em><a target="_blank" href="papers/ALA2019_paper_18.pdf">Autonomous Distributed System using Graph Convolutional Network</a></em></td>
            </tr>
            <tr>
            <td>11:30 - 12:00<br></td>
            <td>Long Talk: Vera Kazakova and Gita Sukthankar<br> <em><a target="_blank" href="papers/ALA2019_paper_21.pdf">Adaptable decentralized task allocation for hierarchically-defined domains</a></em></td>
            </tr>
            <tr>
            <td>12:00 - 12:15</td>
            <td>Short Talk: Farzaneh Shoeleh, Mohammadmehdi Yadollahi and Masoud Asadpour<br><em> <a target="_blank" href="papers/ALA2019_paper_8.pdf">Domain Adaptation based Transfer Learning using Adversarial Network</a></em></td>
            </tr>
            <tr>
            <td>12:15 - 12:30</td>
            <td>Short Talk: Gabriel Ramos, Roxana R&#259;dulescu and Ann Now&eacute;<br><em><a target="_blank" href="papers/ALA2019_paper_30.pdf">A Budged-Balanced Tolling Scheme for Efficient Equilibria under Heterogeneous Preferences</a></em></td>
            </tr>
            <tr>
            <td><b>12:30 - 14:00</b></td>
            <td><b>Lunch</b></td>
            </tr>
            
            <tr>
            <td><b>14:00 - 15:30</b></td>
            <td><b>Session VI - Chair: Patrick MacAlpine</b></td>
            </tr>
            <tr>
            <td>14:00 - 14:15<br></td>
            <td>Short Talk: Pieter Libin, Timothy Verstraeten, Diederik Roijers, Wenjia Wang, Kristof Theys and Ann Now&eacute;<br> <em><a target="_blank" href="papers/ALA2019_paper_9.pdf">Boundary Focused Thompson Sampling</a></em></td>
            </tr>
            <tr>
            <td>14:15 - 14:30<br></td>
            <td>Short Talk: Keiichi Namikoshi and Sachiyo Arai<br> <em><a target="_blank" href="papers/ALA2019_paper_13.pdf">Estimation of agent's rewards using multi-agent maximum discounted causal entropy inverse reinforcement learning</a></em></td>
            </tr>
            <tr>
            <td>14:30 - 14:45<br></td>
            <td>Short Talk: Brian Broll, Matthew Hausknecht and Adith Swaminathan<br> <em><a target="_blank" href="papers/ALA2019_paper_27.pdf">Customizing Scripted Bots: Sample Efficient Imitation Learning for Human-like Behavior in Minecraft</a></em></td>
            </tr>
            <tr>
            <td>14:45 - 15:00<br></td>
            <td>Short Talk: Arno Moonens and Ann Now&eacute;<br> <em><a target="_blank" href="papers/ALA2019_paper_33.pdf">Fine-grained control of electric vehicle charging with policy gradient</a></em></td>
            </tr>
            <tr>
            <td><b>15:00 - 15:30</b><br></td>
            <td><b>Awards, closing remarks and ALA 2020 </b></td>
            </tr>
            <tr>
            <td><b>15:30 - 16:00</b></td>
            <td><b>Coffee Break</b></td>
            </tr>
            
            <tr>
            <td><b>16:00 - 18:00</b></td>
            <td><b><a href="#posterB">Poster Session B</a></b></td>
            </tr>
            
            </table>-->
            </div>
            </section>
        
            <section id="accepted">
                <div class="container">
                    <h3>Accepted Papers</h3>
                    <p>TBA</p>
                    
            
                    <!--
                    <h4 id="longtalks">Long Talks</h4>
                    
                    <table style="width:100%">
                        <tr style="text-align:center">
                            <th>Paper #</th>
                            <th>Authors</th>
                            <th>Title</th>
                        </tr>
                        <tr><td>13</td><td>Ganesh Ghalme, Swapnil Dhamal, Shweta Jain, Sujit Gujar and Y Narahari</td><td><em><a target='_blank' href='papers/ALA2020_paper_13.pdf'> Ballooning Multi-Armed Bandits</a></em></td></tr>
                        <tr><td>17</td><td>Lisa Torrey</td><td><em><a target='_blank' href='papers/ALA2020_paper_17.pdf'> Reinforcement Learning via Reasoning from Demonstration</a></em></td></tr>
                        <tr><td>18</td><td>Daniel Willemsen, Hendrik Baier and Michael Kaisers</td><td><em><a target='_blank' href='papers/ALA2020_paper_18.pdf'> Value targets in off-policy AlphaZero: a new greedy backup</a></em></td></tr>
                        <tr><td>19</td><td>Pieter Libin, Arno Moonens, Timothy Verstraeten, Fabian Perez-Sanjines, Niel Hens, Philippe Lemey and Ann Nowé</td><td><em><a target='_blank' href='papers/ALA2020_paper_19.pdf'> Deep reinforcement learning for large-scale epidemic control</a></em></td></tr>
                        <tr><td>20</td><td>Timothy Verstraeten, Eugenio Bargiacchi, Pieter Libin, Jan Helsen, Diederik Roijers and Ann Nowé</td><td><em><a target='_blank' href='papers/ALA2020_paper_20.pdf'> Thompson Sampling for Loosely-Coupled Multi-Agent Systems: An Application to Wind Farm Control</a></em></td></tr>
                        <tr><td>23</td><td>João Vitor de Oliveira Barbosa, Francisco C. Santos, Francisco S. Melo, Anna Helena Reali Costa and Jaime Simão Sichman</td><td><em><a target='_blank' href='papers/ALA2020_paper_23.pdf'> Emergence of Cooperation in N-Person Dilemmas through Actor-Critic Reinforcement Learning</a></em></td></tr>
                        <tr><td>24</td><td>Panayiotis Danassis and Boi Faltings</td><td><em><a target='_blank' href='papers/ALA2020_paper_24.pdf'> Learning to Persist or Switch: Efficient and Fair Allocations in Large-scale Multi-agent Systems</a></em></td></tr>
                        <tr><td>25</td><td>Silviu Pitis, Harris Chan, Stephen Zhao, Bradly Stadie and Jimmy Ba</td><td><em><a target='_blank' href='papers/ALA2020_paper_25.pdf'> Maximum Entropy Gain Exploration for Long Horizon Multi-goal Reinforcement Learning</a></em></td></tr>
                        <tr><td>28</td><td>Peter Vamplew, Cameron Foale and Richard Dazeley</td><td><em><a target='_blank' href='papers/ALA2020_paper_28.pdf'> A Demonstration of Issues with Value-Based Multiobjective Reinforcement Learning Under Stochastic State Transitions</a></em></td></tr>
                        <tr><td>38</td><td>Grigory Neustroev, Canmanie Ponnambalam, Mathijs de Weerdt and Matthijs Spaan</td><td><em><a target='_blank' href='papers/ALA2020_paper_38.pdf'> Interval Q-Learning: Balancing Deep and Wide Exploration</a></em></td></tr>
                        <tr><td>41</td><td>Yunshu Du, Garrett Warnell, Assefaw Gebremedhin, Peter Stone and Matthew E. Taylor</td><td><em><a target='_blank' href='papers/ALA2020_paper_41.pdf'> Work-in-progress: Corrected Self Imitation learning via Demonstrations</a></em></td></tr>
                        <tr><td>45</td><td>Aly Ibrahim, Anirudha Jitani, Daoud Piracha and Doina Precup</td><td><em><a target='_blank' href='papers/ALA2020_paper_45.pdf'> Reward Redistribution Mechanisms in Multi-agent Reinforcement Learning</a></em></td></tr>
                    </table>
                    
                    <h4 id="shorttalks">Short Talks</h4>
                    
                    <table style="width:100%">
                        <tr style="text-align:center">
                            <th>Paper #</th>
                            <th>Authors</th>
                            <th>Title</th>
                        </tr>
                        <tr><td>1</td><td>Abhik Singla, Sindhu Padakandla and Shalabh Bhatnagar</td><td><em><a target='_blank' href='papers/ALA2020_paper_1.pdf'> Memory-based Deep Reinforcement Learning Method for Obstacle Avoidance in UAV</a></em></td></tr>
                        <tr><td>5</td><td>Hardik Meisheri, Vinita Baniwal, Nazneen N Sultana, Balaraman Ravindran and Harshad Khadilkar</td><td><em><a target='_blank' href='papers/ALA2020_paper_5.pdf'> Using Reinforcement Learning for a Large Variable-Dimensional Inventory Management Problem</a></em></td></tr>
                        <tr><td>8</td><td>Zerong Xi and Gita Sukthankar</td><td><em><a target='_blank' href='papers/ALA2020_paper_8.pdf'> Learning Correlation Functions on Mixed Data Sequences for Computer Architecture Applications</a></em></td></tr>
                        <tr><td>14</td><td>Swapnil Dhamal, Walid Ben-Ameur, Tijani Chahed and Eitan Altman</td><td><em><a target='_blank' href='papers/ALA2020_paper_14.pdf'> A Two Phase Investment Game for Competitive Opinion Dynamics in Social Networks</a></em></td></tr>
                        <tr><td>22</td><td>Xiangyu Liu and Ying Tan</td><td><em><a target='_blank' href='papers/ALA2020_paper_22.pdf'> Feudal Latent Space Exploration for Coordinated Multi-agent Reinforcement Learning</a></em></td></tr>
                        <tr><td>27</td><td>Jiachen Yang, Ang Li, Mehrdad Farajtabar, Peter Sunehag, Edward Hughes and Hongyuan Zha</td><td><em><a target='_blank' href='papers/ALA2020_paper_27.pdf'> Learning to Incentivize Other Learning Agents</a></em></td></tr>
                        <tr><td>29</td><td>Rohit Prasad, Harshad Khadilkar and Shivaram Kalyanakrishnan</td><td><em><a target='_blank' href='papers/ALA2020_paper_29.pdf'> Optimising a Real-time Scheduler for Railway Lines using Policy Search</a></em></td></tr>
                        <tr><td>30</td><td>Paniz Behboudian, Yash Satsangi, Matthew Taylor, Anna Harutyunyan and Michael Bowling</td><td><em><a target='_blank' href='papers/ALA2020_paper_30.pdf'> Useful Policy Invariant Shaping from Arbitrary Advice</a></em></td></tr>
                        <tr><td>32</td><td>Yijie Zhang, Roxana Radulescu, Patrick Mannion, Diederik M. Roijers and Ann Nowé</td><td><em><a target='_blank' href='papers/ALA2020_paper_32.pdf'> Opponent Modelling using Policy Reconstruction for Multi-Objective Normal Form Games</a></em></td></tr>
                        <tr><td>33</td><td>Abhinav Gupta, Agnieszka Słowik, William L. Hamilton, Mateja Jamnik, Sean B. Holden and Christopher Pal</td><td><em><a target='_blank' href='papers/ALA2020_paper_33.pdf'> Analyzing structural priors in multi-agent communication</a></em></td></tr>
                        <tr><td>34</td><td>Hang Xu, Ridhima Bector and Zinovi Rabinovich</td><td><em><a target='_blank' href='papers/ALA2020_paper_34.pdf'> Teaching Multiple Learning Agents by Environment-Dynamics Tweaks</a></em></td></tr>
                        <tr><td>39</td><td>Michael Sullins and Ian Kash</td><td><em><a target='_blank' href='papers/ALA2020_paper_39.pdf'> Increased Optimism in Multi-Agent Policy Gradients</a></em></td></tr>
                        <tr><td>43</td><td>Finbarr Timbers, Edward Lockhart, Martin Schmid, Marc Lanctot and Michael Bowling</td><td><em><a target='_blank' href='papers/ALA2020_paper_43.pdf'> Approximate exploitability: Learning a best response in large games</a></em></td></tr>
                        <tr><td>44</td><td>Arjun Manoharan, Rahul Ramesh and Balaraman Ravindran</td><td><em><a target='_blank' href='papers/ALA2020_paper_44.pdf'> Option Encoder: A Framework for Discovering a Policy Basis in Reinforcement Learning</a></em></td></tr>
                    </table>
                    
                    <h4 id="shorttalks">Spotlight</h4>
                    <table style="width:100%">
                        <tr style="text-align:center">
                            <th>Paper #</th>
                            <th>Authors</th>
                            <th>Title</th>
                        </tr>
                        <tr><td>3</td><td>Budi Kurniawan, Peter Vamplew, Michael Papasimeon, Richard Dazeley and Cameron Foale</td><td><em><a target='_blank' href='papers/ALA2020_paper_3.pdf'> Discrete-to-Deep Supervised Policy Learning: An effective training method for neural reinforcement learning</a></em></td></tr>
                        <tr><td>9</td><td>Saloni Laddha and Shrisha Rao</td><td><em><a target='_blank' href='papers/ALA2020_paper_9.pdf'> Dynamic Interactions by Strong Influencers in Social Networks Using Opinion Propagation</a></em></td></tr>
                        <tr><td>11</td><td>Shripad Salsingikar and Narayan Rangaraj</td><td><em><a target='_blank' href='papers/ALA2020_paper_11.pdf'> Reinforcement Learning for Train Movement Planning at Railway Stations</a></em></td></tr>
                        <tr><td>15</td><td>Wolfram Barfuss</td><td><em><a target='_blank' href='papers/ALA2020_paper_15.pdf'> Infinite population evolutionary dynamics match infinite memory reinforcement learning dynamics</a></em></td></tr>
                        <tr><td>16</td><td>Craig Sherstan, Bilal Kartal, Pablo Hernandez-Leal and Matthew E. Taylor</td><td><em><a target='_blank' href='papers/ALA2020_paper_16.pdf'> Work in Progress: Temporally Extended Auxiliary Tasks</a></em></td></tr>
                        <tr><td>31</td><td>Conor F Hayes, Enda Howley and Patrick Mannion</td><td><em><a target='_blank' href='papers/ALA2020_paper_31.pdf'> Dynamic Thresholded Lexicographic Ordering</a></em></td></tr>
                        <tr><td>35</td><td>Tapan Shah</td><td><em><a target='_blank' href='papers/ALA2020_paper_35.pdf'> State Aware Principal Action Space Embedding for Centralized MARL</a></em></td></tr>
                        <tr><td>36</td><td>Thomy Phan, Lenz Belzner, Kyrill Schmid, Thomas Gabor, Fabian Ritz, Sebastian Feld and Claudia Linnhoff-Popien</td><td><em><a target='_blank' href='papers/ALA2020_paper_36.pdf'> A Distributed Policy Iteration Scheme for Cooperative Multi-Agent Policy Approximation</a></em></td></tr>
                    </table> -->
                    
                </div>
            </section>
            
            <!-- Six -->
            <section id="talks">
                <div class="container">
                    <h3>Invited Talks</h3>
                    
                    
                    <h4>Natasha Jaques</h4>
                    
                    <div style="width:100%;">
                        <div style="width:35%; float:left;"><img src="images/natashajaques.jpg" width="90%" image-orientation="from-image"></div>
                        <div style="width:65%; float:right;">
                            <p><b>Affiliation:</b> Google Brain & UC Berkeley</p>
                            <p><b>Website:</b> <a href="https://natashajaques.ai " target="_blank">https://natashajaques.ai </a></p>
                        </div>
                    </div>
                    <!---<p class="bio" align="justify"><b>Talk Title: Multi-objective decision making: why, how, and what now?</b></p>
                    <p class="bio" align="justify"><b>Abstract: </b>In his invited talk at ALA, Diederik will be discussing: multi-objective decision making. Firstly, he'll focus on why one should model decision problems as explicitly multi-objective, from a practical, as well as a mathematical, and an ethical perspective. Secondly, he'll discuss some lessons learned from his work in multi-objective problems, in the form of tips and tricks for getting started with multiple objectives. To conclude he'll go into the potential, and what he believes are the major open problems in multi-objective decision-making research.</p>--->
                    
                    <p align="justify" class="bio"><b>Bio:</b> Natasha Jaques holds a joint position as a Senior Research Scientist at Google Brain and Visiting Postdoctoral Scholar at UC Berkeley. Her research focuses on Social Reinforcement Learning in multi-agent and human-AI interactions. Natasha completed her PhD at MIT, where her thesis received the Outstanding PhD Dissertation Award from the Association for the Advancement of Affective Computing. Her work has also received Best Demo at NeurIPS, an honourable mention for Best Paper at ICML, Best of Collection in the IEEE Transactions on Affective Computing, and Best Paper at the NeurIPS workshops on ML for Healthcare and Cooperative AI. She has interned at DeepMind, Google Brain, and was an OpenAI Scholars mentor. Her work has been featured in Science Magazine, Quartz, IEEE Spectrum, MIT Technology Review, Boston Magazine, and on CBC radio. Natasha earned her Masters degree from the University of British Columbia, and undergraduate degrees in Computer Science and Psychology from the University of Regina. More about Natasha, but more importantly her research, can be found on her website: <a href="https://natashajaques.ai " target="_blank">https://natashajaques.ai </a></p>

                    <h4>Bei Peng</h4>
                    
                    <div style="width:100%;">
                        <div style="width:35%; float:left;"><img src="images/beipeng.png" width="90%" image-orientation="from-image"></div>
                        <div style="width:65%; float:right;">
                            <p><b>Affiliation:</b> University of Liverpool</p>
                            <p><b>Website:</b> <a href="https://beipeng.github.io/" target="_blank">https://beipeng.github.io/ </a></p>
                        </div>
                    </div>                    
                    
                    <p align="justify" class="bio"><b>Bio:</b> Bei Peng is currently a Lecturer (Assistant Professor) in the Department of Computer Science at the University of Liverpool. Her research focuses mainly on deep reinforcement learning, multi-agent systems, interactive machine learning, and curriculum learning. Prior to Liverpool, Bei was a Postdoctoral Researcher in reinforcement learning at the Whiteson Research Lab at the University of Oxford, and a Non-Stipendiary Lecturer in Computer Science at St Catherine's College. Bei received a B.S. in Computer Science from the Huazhong University of Science and Technology in China in 2012 and a Ph.D. in Computer Science from the Washington State University in 2018. </a></p>

                    <p></p>
                    
                    <h4>Patrick MacAlpine</h4>
                    
                    <div style="width:100%;">
                        <div style="width:35%; float:left;"><img src="images/patrick.JPG" width="90%" image-orientation="from-image"></div>
                        <div style="width:65%; float:right;">
                            <p><b>Affiliation:</b> Sony AI</p>
                        </div>
                    </div>
                    <p align="justify" class="bio"><b>Bio:</b> Patrick MacAlpine is a research scientist at Sony AI, and his research spans the areas of autonomous multiagent systems, robotics, and machine learning with an emphasis on reinforcement learning.  He completed a Ph.D. in the computer science department at the University of Texas at Austin where he was advised by Peter Stone.  During his Ph.D. Patrick served as the team leader of the robot soccer UT Austin Villa RoboCup 3D Simulation League team, and much of his dissertation work contributed to the team winning the RoboCup 3D Simulation League world championship multiple years.  Patrick received both bachelor’s and master’s degrees in electrical engineering from Rice University.  Prior to joining Sony AI, Patrick was a postdoctoral researcher in the reinforcement learning group at Microsoft Research. </a></p>                    
                    
                    <p align="justify" class="title"><b>Title:</b> Outracing Champion Gran Turismo Drivers with Deep Reinforcement Learning</a></p>

                    <p align="justify" class="abstract"><b>Abstract:</b> Many potential applications of artificial intelligence involve making real-time decisions in physical systems while interacting with humans. Automobile racing represents an extreme example of these conditions; drivers must execute complex tactical manoeuvres to pass or block opponents while operating their vehicles at their traction limits. Racing simulations, such as the PlayStation game Gran Turismo, faithfully reproduce the non-linear control challenges of real race cars while also encapsulating the complex multi-agent interactions. Here we describe how we trained agents for Gran Turismo that can compete with the world’s best e-sports drivers. We combine state-of-the-art, model-free, deep reinforcement learning algorithms with mixed-scenario training to learn an integrated control policy that combines exceptional speed with impressive tactics. In addition, we construct a reward function that enables the agent to be competitive while adhering to racing’s important, but under-specified, sportsmanship rules. We demonstrate the capabilities of our agent, Gran Turismo Sophy, by winning a head-to-head competition against four of the world’s best Gran Turismo drivers. By describing how we trained championship-level racers, we demonstrate the possibilities and challenges of using these techniques to control complex dynamical systems in domains where agents must respect imprecisely defined human norms. </a></p>

                    
                   
                    <p class="entry-footer"></p>                   
                    
                    
                   
                </div>
            </section>
            
            
            <!-- Seven -->
            <section id="pc">
                <div class="container">
                    <h3>Programe Committee</h3>         
        
                    <ul>
                        <li>Erman Acar, Leiden University & VU Amsterdam, NL</li>
                            <li>Adrian Agogino, University of California Santa Cruz, USA</li>
                            <li>Nicolas Anastassacos, University College London, UK</li>
                            <li>Raphael Avalos, Vrije Universiteit Brussel, BE</li>
                            <li>Angel Ayala, Universidade de Pernambuco, BR</li>
                            <li>Wolfram Barfuss, Tuebingen AI Center, University of Tuebingen, GE</li>
                            <li>Pablo Barros, University of Hamburg, GE</li>
                            <li>Daan Bloembergen, City of Amsterdam, NL</li>
                            <li>Rodrigo Bonini, Federal University of ABC, BR</li>
                            <li>Roland Bouffanais, University of Ottawa, CA</li>
                            <li>Mustafa Mert Çelikok, Aalto University, FI</li>
                            <li>Filippos Christianos, University of Edinburgh, UK</li>
                            <li>Raphael Cobe, Sao Paulo State University, BR</li>
                            <li>Vinicius Renan de Carvalho, University of São Paulo, BR</li>
                            <li>Yunshu Du, Sony AI, US</li>
                            <li>Elias Fernández Domingos, Vrije Universiteit Brussels, BE</li>
                            <li>Marek Grzes, University of Kent, BE</li>
                            <li>Brent Harrison, University of Kentucky, US</li>
                            <li>Fredrik Heintz, Linköping University, SE</li>
                            <li>Daniel Hernandez, University of York, UK</li>
                            <li>Johan Källström, Linköping University, SE</li>
                            <li>Thommen Karimpanal George, Deakin University, AU</li>
                            <li>Sammie Katt, Northeastern University, US</li>
                            <li>Mari Kawakatsu, Princeton University, US</li>
                            <li>Matt Knudson, NASA, US</li>
                            <li>Mikel Landajuela, Lawrence Livermore National Laboratory, US</li>
                            <li>Guangliang Li, Ocean University of China, CN</li>
                            <li>Pieter Libin, Vrije Universiteit Brussel, BE</li>
                            <li>Udari Madhushani, Princeton University, US</li>
                            <li>Kleanthis Malialis, University of Cyprus, CY</li>
                            <li>Karl Mason, Georgia Institute of Technology, US</li>
                            <li>Cristian Camilo Millán Arias, Universidade de Pernambuco, BR</li>
                            <li>Nicolás Navarro-Guerrero, Deutsches Forschungszentrum für Künstliche Intelligenz, GE</li>
                            <li>Bei Peng, University of Liverpool, UK</li>
                            <li>Hélène Plisnier, Vrije Universiteit Brussel, BE</li>
                            <li>Canmanie Ponnambalam, Delft University of Technology, NL</li>
                            <li>Roxana Radulescu, Vrije Universiteit Brussel, BE</li>
                            <li>Pablo Hernandez-Leal, Borealis AI, CA</li>
                            <li>Gabriel De O. Ramos, Universidade do Vale do Rio dos Sinos, BR</li>
                            <li>Diederik M. Roijers, Vrije Universiteit Brussel & HU University of Applied Sciences Utrecht, NL</li>
                            <li>Willem Röpke, Vrije Universiteit Brussel, BE</li>
                            <li>Francisco C. Santos, INESC-ID and Instituto Superior Técnico, Universidade de Lisboa, PT</li>
                            <li>Craig Sherstan, University of Alberta, CA</li>
                            <li>Alexey Shpilman, JetBrains Research, HSE University, RU</li>
                            <li>Jivko Sinapov, The University of Texas at Austin, US</li>
                            <li>Miguel Solis, Universidad Andrés Bello, CL</li>
                            <li>Miguel Suau, Delft Univesity of Technology, NL</li>
                            <li>Paolo Turrini, University of Warwick, UK</li>
                            <li>Victor Uc-Cetina, Universidad Autónoma de Yucatán, MX</li>
                            <li>Peter Vamplew, Federation University Australia, AU</li>
                            <li>Miguel Vasco, INESC-ID and Instituto Superior Técnico, Universidade de Lisboa, PT</li>
                            <li>Vítor V. Vasconcelos, University of Amsterdam, NL</li>
                            <li>Connor Yates, Oregon State University, US</li>
                    </ul>
                    
                </div>
            </section>
            
            
            <!-- eight -->
            <section id="organization">
                <div class="container">
                    <h3>Organization</h3>
                    This year's workshop is organised by:
                    <ul>
                        <li><a href="http://www.franciscocruz.cl/?i=1" target="_blank">Francisco Cruz</a> (Deakin University, AUS) </li>
                        <li><a href="https://conorfhayes.info" target="_blank">Conor F. Hayes</a> (National University of Ireland Galway, IE) </li>
                        <li><a href="https://f-leno.github.io" target="_blank">Felipe Leno da Silva</a> (Lawrence Livermore National Lab, USA) </li>
                        <li><a href="https://web.ist.utl.pt/~fernando.pedro/" target="_blank">Fernando P. Santos</a> (University of Amsterdam, NL)</li>
                    </ul>
                    
                    Senior Steering Committee Members:
                    <ul>
                        <li>Enda Howley (National University of Ireland Galway, IE)</li>
                        <li>Daniel Kudenko (University of York, UK)</li>
                        <li>Patrick Mannion (National University of Ireland Galway, IE)</li>
                        <li>Ann Now&eacute; (Vrije Universiteit Brussel, BE)</li>
                        <li>Sandip Sen (University of Tulsa, US)</li>
                        <li>Peter Stone (University of Texas at Austin, US)</li>
                        <li>Matthew Taylor (Washington State University, US)</li>
                        <li>Kagan Tumer (Oregon State University, US)</li>
                        <li>Karl Tuyls (University of Liverpool, UK)</li>
                    </ul>
                </div>
            </section>
            
            
            
            <section id="sponsor">
                <div class="container">
                    <h3>Sponsorship</h3>
                    <p align="justify">The ALA 2022 Best Paper Award is kindly sponsored by the Springer journal <a href="https://www.springer.com/computer/ai/journal/521" target="_blank"> Neural Computing and Applications</a>.</p>
                    <a href="https://www.springer.com/computer/ai/journal/521" target='_blank'><img src='images/nca.jpg' height='200px' alt='NCA' /></a>
                </div>
            </section>

            <section id="ai_ethics">
                <div class="container">
                    <h3>Trustworthy Adaptive and Learning Agents</h3>
                    <p align="justify">Authors and attendees of ALA 2022 who are interested in trustworthiness in agent-based systems are invited to submit their work to a topical collection (TC) on Trustworthy Adaptive and Learning Agents (TALA).
                    This TC solicits original research articles, reviews/surveys, and opinion pieces/commentaries relating to trustworthiness in agent-based systems, including those that employ learning and/or adaptation.
                    The TALA TC has an open call for papers; it is not necessary to submit preliminary work to the ALA workshop in order to have your manuscript considered for publication in this TC.</p>
                    <p align="justify"><a href="https://www.springer.com/journal/43681/updates/19318686" target="_blank"> AI and Ethics</a></p>
                    <a href="https://www.springer.com/computer/ai/journal/521" target='_blank'><img src='images/ai_ethics.jpg' height='200px' alt='NCA' /></a>
                </div>
            </section>
            
            <!-- ten -->
            <section id="contact">
                <div class="container">
                    <h3>Contact</h3>
                    <p align="justify">If you have any questions about the ALA workshop, please contact the organizers at: <br/>
                    ala.workshop.2022 AT gmail.com
                    </p>
                    <p> For more general news, discussion, collaboration and networking opportunities with others interested in Adaptive Learning Agents then please join our Linkedin Group
                    <a class="fa" href="https://www.linkedin.com/groups/4412140/" >
                        <i class="fa fa-linkedin"></i>
                    </a> </p>
                </div>
                
                </div>
        </section>
        
        <!-- Footer -->
        <section id="footer">
            <div class="container">
                <ul class="copyright">
                    <li>&copy; Adaptive Learning Agents Workshop 2022. All rights reserved.</li>
                    <li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
                    <li>Icons made by <a href="https://www.flaticon.com/authors/freepik" title="Freepik">Freepik</a> from <a href="https://www.flaticon.com/" title="Flaticon">www.flaticon.com</a> are licensed by <a href="http://creativecommons.org/licenses/by/3.0/" title="Creative Commons BY 3.0" target="_blank">CC 3.0 BY</a></li>
                </ul>
            </div>
        </section>
        
        </div>
        
        <!-- Scripts -->
        <script src="assets/js/jquery.min.js"></script>
        <script src="assets/js/jquery.scrollex.min.js"></script>
        <script src="assets/js/jquery.scrolly.min.js"></script>
        <script src="assets/js/browser.min.js"></script>
        <script src="assets/js/breakpoints.min.js"></script>
        <script src="assets/js/util.js"></script>
        <script src="assets/js/main.js"></script>
        
    </body>
</html>
